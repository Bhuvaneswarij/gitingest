{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTUOwsQViycziPg7PwUGrQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhuvaneswarij/gitingest/blob/main/Time%20series%20method1_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfxX3JrOKkpK",
        "outputId": "11e8e368-a758-468a-feb2-fc6c276f2c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded:  (203, 7)\n",
            "             realgdp  realcons  realinv  realgovt  realdpi    cpi  \\\n",
            "1959-01-01  2710.349    1707.4  286.898   470.045   1886.9  28.98   \n",
            "1959-04-01  2778.801    1733.7  310.859   481.301   1919.7  29.15   \n",
            "1959-07-01  2775.488    1751.8  289.226   491.260   1916.4  29.35   \n",
            "1959-10-01  2785.204    1753.7  299.356   484.052   1931.3  29.37   \n",
            "1960-01-01  2847.699    1770.5  331.722   462.199   1955.5  29.54   \n",
            "\n",
            "            unemployment  \n",
            "1959-01-01           5.8  \n",
            "1959-04-01           5.1  \n",
            "1959-07-01           5.3  \n",
            "1959-10-01           5.6  \n",
            "1960-01-01           5.2  \n",
            "After feature engineering: (199, 23)\n",
            "Train/test shapes: (143, 8, 22) (48, 8, 22) (143,) (48,)\n",
            "MC LSTM trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantile LSTM trained.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step\n",
            "\n",
            "=== POINT FORECAST METRICS ===\n",
            "MC LSTM: MAE=1.1065, RMSE=1.3170, MAPE=20.08%\n",
            "Quantile LSTM (median): MAE=1.3504, RMSE=1.5293, MAPE=25.03%\n",
            "SARIMAX: MAE=0.8210, RMSE=1.2710, MAPE=13.83%\n",
            "Prophet: MAE=1.1127, RMSE=1.4634, MAPE=22.24%\n",
            "\n",
            "=== UNCERTAINTY METRICS (ICP, MIW) ===\n",
            "MC LSTM 80%: ICP=0.125, MIW=1.0116974115371704, n=48\n",
            "MC LSTM 95%: ICP=0.2916666666666667, MIW=1.515511393547058, n=48\n",
            "Quantile LSTM 80%: ICP=0.3125, MIW=0.754157543182373, n=48\n",
            "Quantile LSTM 95%: ICP=0.875, MIW=1.8983834981918335, n=48\n",
            "SARIMAX 80%: ICP=1.0, MIW=7.3749660714157175, n=48\n",
            "SARIMAX 95%: ICP=1.0, MIW=11.346101648331873, n=48\n",
            "Prophet 80%: ICP=0.5416666666666666, MIW=2.003576122927335, n=48\n",
            "Prophet 95%: ICP=0.6458333333333334, MIW=3.0824248045035922, n=48\n",
            "\n",
            "\n",
            "==================== DETAILED ANALYSIS REPORT ====================\n",
            "\n",
            "Dataset:\n",
            " - Source: statsmodels.datasets.macrodata (quarterly)\n",
            " - Features used: ['realgdp', 'realcons', 'realinv', 'realgovt', 'realdpi', 'cpi', 'gdp_pct', 'cons_pct', 'inv_pct', 'unemp_lag1', 'gdp_lag1', 'unemp_lag2', 'gdp_lag2', 'unemp_lag3', 'gdp_lag3', 'unemp_lag4', 'gdp_lag4', 'unemp_roll_mean_4', 'unemp_roll_std_4', 'q_2', 'q_3', 'q_4']\n",
            " - Sequence length (history): 8 quarters\n",
            "\n",
            "Point Forecast Comparison:\n",
            " - MC LSTM: MAE=1.1065, RMSE=1.3170, MAPE=20.08%\n",
            " - Quantile LSTM (median): MAE=1.3504, RMSE=1.5293, MAPE=25.03%\n",
            " - SARIMAX: MAE=0.8210, RMSE=1.2710, MAPE=13.83%\n",
            " - Prophet: MAE=1.1127, RMSE=1.4634, MAPE=22.24%\n",
            "\n",
            "Uncertainty (Prediction Interval) Comparison:\n",
            " - MC LSTM 80%: ICP=0.125, MIW=1.012 (n=48)\n",
            " - MC LSTM 95%: ICP=0.292, MIW=1.516 (n=48)\n",
            " - Quantile LSTM 80%: ICP=0.312, MIW=0.754 (n=48)\n",
            " - Quantile LSTM 95%: ICP=0.875, MIW=1.898 (n=48)\n",
            " - SARIMAX 80%: ICP=1.000, MIW=7.375 (n=48)\n",
            " - SARIMAX 95%: ICP=1.000, MIW=11.346 (n=48)\n",
            " - Prophet 95%: ICP=0.646, MIW=3.082\n",
            "\n",
            "Interpretation guidelines:\n",
            " - ICP (Interval Coverage Probability): fraction of true values lying inside the PI. For an 80% PI target ~0.8, for a 95% PI target ~0.95.\n",
            " - MIW (Mean Interval Width): average width of the PIs; narrower is better if ICP is near nominal target. Trade-off: too narrow -> low ICP; too wide -> less useful.\n",
            "\n",
            "Model strengths / weaknesses (expected):\n",
            " - MC LSTM: flexible, captures complex nonlinearities; MC Dropout provides model-driven epistemic uncertainty. Check whether ICPs are near nominal levels.\n",
            " - Quantile LSTM: can directly optimize different quantiles; tends to produce sharper intervals when trained well.\n",
            " - SARIMAX: classical, may be competitive for linear seasonal series; intervals are parametric and rely on model assumptions.\n",
            " - Prophet: robust for trend+seasonality and business time series; uncertainty is based on simulated components and may be wider/narrower depending on trend assumptions.\n",
            "\n",
            "Practical next steps:\n",
            " 1) If ICP significantly below nominal -> increase model capacity or use ensembling/heteroscedastic modeling.\n",
            " 2) If MIW too large -> retrain quantile model with stronger regularization or add relevant predictors.\n",
            " 3) Cross-validate interval calibration using rolling-window CV and adjust quantile calibration post-hoc if necessary.\n",
            "\n",
            "=================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Try prophet import (optional)\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "    PROPHET_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    PROPHET_AVAILABLE = False\n",
        "    _prophet_error = str(e)\n",
        "\n",
        "# ----------------------\n",
        "# 1) Load dataset\n",
        "# ----------------------\n",
        "data = sm.datasets.macrodata.load_pandas().data\n",
        "# macrodata columns include: year, quarter, realgdp, realcons, realinv, realgovt, realdpi, cpi, m1, tbilrate, unemployment, pop\n",
        "# convert to a datetime index (quarterly)\n",
        "dates = pd.PeriodIndex(year=data['year'].astype(int), quarter=data['quarter'].astype(int), freq='Q').to_timestamp()\n",
        "df = data.copy()\n",
        "df.index = dates\n",
        "df = df[['realgdp','realcons','realinv','realgovt','realdpi','cpi','unemp']]  # selected multivariate\n",
        "df = df.rename(columns={'unemp':'unemployment'})  # nicer name\n",
        "df = df.sort_index()\n",
        "print(\"Dataset loaded: \", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# ----------------------\n",
        "# 2) Expanded feature engineering\n",
        "# ----------------------\n",
        "def add_features(df):\n",
        "    df_fe = df.copy()\n",
        "    # percent changes\n",
        "    df_fe[['gdp_pct','cons_pct','inv_pct']] = df_fe[['realgdp','realcons','realinv']].pct_change()\n",
        "    # lags for target (unemployment) and main predictors\n",
        "    for lag in [1,2,3,4]:\n",
        "        df_fe[f'unemp_lag{lag}'] = df_fe['unemployment'].shift(lag)\n",
        "        df_fe[f'gdp_lag{lag}'] = df_fe['realgdp'].shift(lag)\n",
        "    # rolling stats\n",
        "    df_fe['unemp_roll_mean_4'] = df_fe['unemployment'].rolling(window=4).mean()\n",
        "    df_fe['unemp_roll_std_4'] = df_fe['unemployment'].rolling(window=4).std()\n",
        "    # seasonality: quarter dummies (one-hot)\n",
        "    df_fe['quarter'] = df_fe.index.quarter\n",
        "    quarter_dummies = pd.get_dummies(df_fe['quarter'], prefix='q', drop_first=True)\n",
        "    df_fe = pd.concat([df_fe, quarter_dummies], axis=1)\n",
        "    df_fe = df_fe.drop(columns=['quarter'])\n",
        "    df_fe = df_fe.dropna()\n",
        "    return df_fe\n",
        "\n",
        "df_fe = add_features(df)\n",
        "print(\"After feature engineering:\", df_fe.shape)\n",
        "\n",
        "# ----------------------\n",
        "# 3) Train/test split & scaling\n",
        "# ----------------------\n",
        "TARGET = 'unemployment'\n",
        "feature_cols = [c for c in df_fe.columns if c != TARGET]\n",
        "X_all = df_fe[feature_cols].values\n",
        "y_all = df_fe[TARGET].values.reshape(-1,1)\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X_all)\n",
        "y_scaled = scaler_y.fit_transform(y_all)\n",
        "\n",
        "# create sequences for LSTM\n",
        "SEQ_LEN = 8  # use 2 years of quarterly history by default (8 quarters)\n",
        "def create_sequences(X, y, seq_len=SEQ_LEN):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(seq_len, len(X)):\n",
        "        Xs.append(X[i-seq_len:i])\n",
        "        ys.append(y[i])\n",
        "    return np.array(Xs), np.array(ys).squeeze()\n",
        "\n",
        "X_seq, y_seq = create_sequences(X_scaled, y_scaled, SEQ_LEN)\n",
        "# split\n",
        "train_size = int(0.75 * len(X_seq))\n",
        "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
        "y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
        "print(\"Train/test shapes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# helper to invert scaling\n",
        "def inv_y(y_scaled_vector):\n",
        "    y_scaled_vector = np.array(y_scaled_vector).reshape(-1,1)\n",
        "    return scaler_y.inverse_transform(y_scaled_vector).flatten()\n",
        "\n",
        "# ----------------------\n",
        "# 4) Build MC Dropout LSTM (point + UQ via MC sampling)\n",
        "# ----------------------\n",
        "def build_mc_lstm(input_shape, dropout_rate=0.2):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.LSTM(64, return_sequences=True)(inp)\n",
        "    x = layers.Dropout(dropout_rate)(x, training=True)  # ensure dropout active for MC sampling\n",
        "    x = layers.LSTM(32)(x)\n",
        "    x = layers.Dropout(dropout_rate)(x, training=True)\n",
        "    out = layers.Dense(1)(x)\n",
        "    model = models.Model(inp, out)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "mc_model = build_mc_lstm((SEQ_LEN, X_train.shape[2]), dropout_rate=0.2)\n",
        "mc_model.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0)\n",
        "print(\"MC LSTM trained.\")\n",
        "\n",
        "# MC prediction function (keep dropout active)\n",
        "def mc_predict(model, X, sims=200):\n",
        "    preds = []\n",
        "    for i in range(sims):\n",
        "        p = model(X, training=True).numpy().flatten()\n",
        "        preds.append(p)\n",
        "    preds = np.array(preds)  # shape (sims, n_samples)\n",
        "    return preds\n",
        "\n",
        "# ----------------------\n",
        "# 5) Quantile Regression LSTM\n",
        "# ----------------------\n",
        "# We'll predict quantiles: 0.025, 0.10, 0.5, 0.9, 0.975  -> use these to form 80% (10-90) and 95% (2.5-97.5)\n",
        "quantiles = [0.025, 0.10, 0.5, 0.9, 0.975]\n",
        "def quantile_loss(q):\n",
        "    def loss(y_true, y_pred):\n",
        "        e = y_true - y_pred\n",
        "        return tf.reduce_mean(tf.maximum(q*e, (q-1)*e))\n",
        "    return loss\n",
        "\n",
        "def build_quantile_lstm(input_shape):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    x = layers.LSTM(64)(inp)\n",
        "    # one dense per quantile\n",
        "    outputs = [layers.Dense(1, name=f'q_{int(q*1000)}')(x) for q in quantiles]\n",
        "    model = models.Model(inp, outputs)\n",
        "    model.compile(optimizer='adam', loss=[quantile_loss(q) for q in quantiles])\n",
        "    return model\n",
        "\n",
        "q_model = build_quantile_lstm((SEQ_LEN, X_train.shape[2]))\n",
        "# prepare y repeated per output\n",
        "y_train_list = [y_train for _ in quantiles]\n",
        "q_model.fit(X_train, y_train_list, epochs=40, batch_size=16, verbose=0)\n",
        "print(\"Quantile LSTM trained.\")\n",
        "\n",
        "# ----------------------\n",
        "# 6) Classical benchmarks: SARIMAX (on unemployment series) and Prophet (if available)\n",
        "# ----------------------\n",
        "# SARIMAX on the original unemployment series aligned with sequences' last indices.\n",
        "unemp_series = df_fe[TARGET]\n",
        "# For SARIMAX forecast we need aligned index range: we will use last len(y_test) observations as hold-out\n",
        "sarimax_train_end = df_fe.index[train_size + SEQ_LEN - 1]  # end date of training period\n",
        "sar_model = SARIMAX(unemp_series[:sarimax_train_end], order=(1,1,1), seasonal_order=(0,0,0,0), enforce_stationarity=False, enforce_invertibility=False)\n",
        "sar_res = sar_model.fit(disp=False)\n",
        "sar_forecast = sar_res.get_forecast(steps=len(y_test))\n",
        "sar_pred = sar_forecast.predicted_mean.values\n",
        "sar_ci = sar_forecast.conf_int(alpha=0.05)  # 95% CI from SARIMAX (if available)\n",
        "\n",
        "# Prophet (optional): we must assemble ds,y dataframe\n",
        "prophet_pred = None\n",
        "prophet_df = None\n",
        "if PROPHET_AVAILABLE:\n",
        "    prop_df = pd.DataFrame({'ds': df_fe.index, 'y': df_fe[TARGET].values})\n",
        "    prophet = Prophet()\n",
        "    prophet.fit(prop_df[:len(prop_df)-len(y_test)])\n",
        "    future = prophet.make_future_dataframe(periods=len(y_test), freq='Q')\n",
        "    forecast = prophet.predict(future)\n",
        "    prophet_pred = forecast['yhat'].values[-len(y_test):]\n",
        "    prophet_lower95 = forecast['yhat_lower'].values[-len(y_test):]\n",
        "    prophet_upper95 = forecast['yhat_upper'].values[-len(y_test):]\n",
        "else:\n",
        "    print(\"Prophet is not available in this environment. To enable Prophet, install with 'pip install prophet' and rerun.\")\n",
        "    print(\"Prophet import error (first lines):\", _prophet_error[:200])\n",
        "\n",
        "# ----------------------\n",
        "# 7) Predictions + UQ\n",
        "# ----------------------\n",
        "# MC-LSTM preds\n",
        "mc_sims = 300\n",
        "mc_preds_scaled = mc_predict(mc_model, X_test, sims=mc_sims)  # shape (sims, n_samples)\n",
        "# derive percentiles for 80% and 95%\n",
        "mc_lower_80 = np.percentile(mc_preds_scaled, 10, axis=0)\n",
        "mc_upper_80 = np.percentile(mc_preds_scaled, 90, axis=0)\n",
        "mc_lower_95 = np.percentile(mc_preds_scaled, 2.5, axis=0)\n",
        "mc_upper_95 = np.percentile(mc_preds_scaled, 97.5, axis=0)\n",
        "mc_mean_scaled = mc_preds_scaled.mean(axis=0)\n",
        "\n",
        "# invert scaling\n",
        "mc_mean = inv_y(mc_mean_scaled)\n",
        "mc_l80 = inv_y(mc_lower_80)\n",
        "mc_u80 = inv_y(mc_upper_80)\n",
        "mc_l95 = inv_y(mc_lower_95)\n",
        "mc_u95 = inv_y(mc_upper_95)\n",
        "\n",
        "# Quantile LSTM preds\n",
        "q_preds_scaled = q_model.predict(X_test)  # list of arrays -> one per quantile\n",
        "# ordering matches quantiles list\n",
        "q_dict = {}\n",
        "for i, q in enumerate(quantiles):\n",
        "    q_dict[q] = q_preds_scaled[i].flatten()\n",
        "\n",
        "# invert\n",
        "q_inv = {q: inv_y(q_dict[q]) for q in quantiles}\n",
        "q_median = q_inv[0.5]\n",
        "q_l80 = q_inv[0.10]\n",
        "q_u80 = q_inv[0.90]\n",
        "q_l95 = q_inv[0.025]\n",
        "q_u95 = q_inv[0.975]\n",
        "\n",
        "# SARIMAX invert -> sar_pred already in original scale because sarimax trained on original series\n",
        "sar_pred = sar_pred  # array in original units\n",
        "# For SARIMAX we may not have 80% intervals; we will compute 95% from sar_ci if available; compute 80% approx by widening/assuming normality\n",
        "if 'lower unemp' in sar_ci.columns or 'lower unemployment' in sar_ci.columns:\n",
        "    pass\n",
        "# But sar_ci columns will be like ['lower y', 'upper y'] for the variable; handle generically\n",
        "if sar_ci.shape[1] == 2:\n",
        "    sar_lower95 = sar_ci.iloc[:,0].values\n",
        "    sar_upper95 = sar_ci.iloc[:,1].values\n",
        "    # approximate 80% by linear interpolation between mean and 95% boundaries (not ideal, but gives an estimate)\n",
        "    sar_lower80 = sar_lower95 * 0.65 + sar_pred * 0.35\n",
        "    sar_upper80 = sar_upper95 * 0.65 + sar_pred * 0.35\n",
        "else:\n",
        "    sar_lower95 = np.full_like(sar_pred, np.nan)\n",
        "    sar_upper95 = np.full_like(sar_pred, np.nan)\n",
        "    sar_lower80 = np.full_like(sar_pred, np.nan)\n",
        "    sar_upper80 = np.full_like(sar_pred, np.nan)\n",
        "\n",
        "# Prophet output (already in original scale) if available\n",
        "if PROPHET_AVAILABLE:\n",
        "    prop_mean = prophet_pred\n",
        "    prop_l95 = prophet_lower95\n",
        "    prop_u95 = prophet_upper95\n",
        "    # attempt 80% by interpolation similar to SARIMAX (or compute 10th/90th if Prophet provided—Prophet gives 80% if you request)\n",
        "    prop_l80 = prop_l95 * 0.65 + prop_mean * 0.35\n",
        "    prop_u80 = prop_u95 * 0.65 + prop_mean * 0.35\n",
        "\n",
        "# ----------------------\n",
        "# 8) Evaluation metrics (point predictions)\n",
        "# ----------------------\n",
        "def mae(y_true, y_pred): return mean_absolute_error(y_true, y_pred)\n",
        "def rmse(y_true, y_pred): return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "def mape(y_true, y_pred): return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# true y_test in original scale\n",
        "y_true = inv_y(y_test)\n",
        "\n",
        "results = {}\n",
        "\n",
        "# MC LSTM\n",
        "results['MC LSTM'] = {\n",
        "    'MAE': mae(y_true, mc_mean),\n",
        "    'RMSE': rmse(y_true, mc_mean),\n",
        "    'MAPE': mape(y_true, mc_mean)\n",
        "}\n",
        "\n",
        "# Quantile median\n",
        "results['Quantile LSTM (median)'] = {\n",
        "    'MAE': mae(y_true, q_median),\n",
        "    'RMSE': rmse(y_true, q_median),\n",
        "    'MAPE': mape(y_true, q_median)\n",
        "}\n",
        "\n",
        "# SARIMAX\n",
        "results['SARIMAX'] = {\n",
        "    'MAE': mae(y_true, sar_pred),\n",
        "    'RMSE': rmse(y_true, sar_pred),\n",
        "    'MAPE': mape(y_true, sar_pred)\n",
        "}\n",
        "\n",
        "# Prophet (if present)\n",
        "if PROPHET_AVAILABLE:\n",
        "    results['Prophet'] = {\n",
        "        'MAE': mae(y_true, prop_mean),\n",
        "        'RMSE': rmse(y_true, prop_mean),\n",
        "        'MAPE': mape(y_true, prop_mean)\n",
        "    }\n",
        "\n",
        "# ----------------------\n",
        "# 9) Uncertainty metrics: ICP and MIW for each model and both intervals (80% & 95%)\n",
        "# ----------------------\n",
        "def interval_metrics(y_true, lower, upper):\n",
        "    y_true = np.array(y_true)\n",
        "    lower = np.array(lower)\n",
        "    upper = np.array(upper)\n",
        "    # remove NaNs pairs\n",
        "    mask = ~(np.isnan(lower) | np.isnan(upper))\n",
        "    if mask.sum() == 0:\n",
        "        return {'ICP': np.nan, 'MIW': np.nan}\n",
        "    covered = (y_true[mask] >= lower[mask]) & (y_true[mask] <= upper[mask])\n",
        "    ICP = covered.mean()\n",
        "    MIW = np.mean(upper[mask] - lower[mask])\n",
        "    return {'ICP': ICP, 'MIW': MIW, 'n': mask.sum()}\n",
        "\n",
        "uq_results = {}\n",
        "\n",
        "# MC LSTM intervals\n",
        "uq_results['MC LSTM 80%'] = interval_metrics(y_true, mc_l80, mc_u80)\n",
        "uq_results['MC LSTM 95%'] = interval_metrics(y_true, mc_l95, mc_u95)\n",
        "\n",
        "# Quantile LSTM intervals\n",
        "uq_results['Quantile LSTM 80%'] = interval_metrics(y_true, q_l80, q_u80)\n",
        "uq_results['Quantile LSTM 95%'] = interval_metrics(y_true, q_l95, q_u95)\n",
        "\n",
        "# SARIMAX intervals\n",
        "uq_results['SARIMAX 80%'] = interval_metrics(y_true, sar_lower80, sar_upper80)\n",
        "uq_results['SARIMAX 95%'] = interval_metrics(y_true, sar_lower95, sar_upper95)\n",
        "\n",
        "# Prophet intervals if available\n",
        "if PROPHET_AVAILABLE:\n",
        "    uq_results['Prophet 80%'] = interval_metrics(y_true, prop_l80, prop_u80)\n",
        "    uq_results['Prophet 95%'] = interval_metrics(y_true, prop_l95, prop_u95)\n",
        "\n",
        "# ----------------------\n",
        "# 10) Print summary results\n",
        "# ----------------------\n",
        "print(\"\\n=== POINT FORECAST METRICS ===\")\n",
        "for model, r in results.items():\n",
        "    print(f\"{model}: MAE={r['MAE']:.4f}, RMSE={r['RMSE']:.4f}, MAPE={r['MAPE']:.2f}%\")\n",
        "\n",
        "print(\"\\n=== UNCERTAINTY METRICS (ICP, MIW) ===\")\n",
        "for k, v in uq_results.items():\n",
        "    print(f\"{k}: ICP={v['ICP']}, MIW={v['MIW']}, n={v.get('n', None)}\")\n",
        "\n",
        "# ----------------------\n",
        "# 11) Detailed text-based analysis report (prints)\n",
        "# ----------------------\n",
        "def print_analysis(results, uq_results):\n",
        "    print(\"\\n\\n==================== DETAILED ANALYSIS REPORT ====================\\n\")\n",
        "    print(\"Dataset:\")\n",
        "    print(f\" - Source: statsmodels.datasets.macrodata (quarterly)\")\n",
        "    print(f\" - Features used: {feature_cols}\")\n",
        "    print(f\" - Sequence length (history): {SEQ_LEN} quarters\")\n",
        "    print(\"\\nPoint Forecast Comparison:\")\n",
        "    for m, r in results.items():\n",
        "        print(f\" - {m}: MAE={r['MAE']:.4f}, RMSE={r['RMSE']:.4f}, MAPE={r['MAPE']:.2f}%\")\n",
        "    print(\"\\nUncertainty (Prediction Interval) Comparison:\")\n",
        "    for model_name in ['MC LSTM 80%','MC LSTM 95%','Quantile LSTM 80%','Quantile LSTM 95%','SARIMAX 80%','SARIMAX 95%']:\n",
        "        if model_name in uq_results:\n",
        "            v = uq_results[model_name]\n",
        "            print(f\" - {model_name}: ICP={v['ICP']:.3f}, MIW={v['MIW']:.3f} (n={v.get('n',None)})\")\n",
        "    if PROPHET_AVAILABLE:\n",
        "        v = uq_results.get('Prophet 95%')\n",
        "        if v:\n",
        "            print(f\" - Prophet 95%: ICP={v['ICP']:.3f}, MIW={v['MIW']:.3f}\")\n",
        "    print(\"\\nInterpretation guidelines:\")\n",
        "    print(\" - ICP (Interval Coverage Probability): fraction of true values lying inside the PI. For an 80% PI target ~0.8, for a 95% PI target ~0.95.\")\n",
        "    print(\" - MIW (Mean Interval Width): average width of the PIs; narrower is better if ICP is near nominal target. Trade-off: too narrow -> low ICP; too wide -> less useful.\")\n",
        "    print(\"\\nModel strengths / weaknesses (expected):\")\n",
        "    print(\" - MC LSTM: flexible, captures complex nonlinearities; MC Dropout provides model-driven epistemic uncertainty. Check whether ICPs are near nominal levels.\")\n",
        "    print(\" - Quantile LSTM: can directly optimize different quantiles; tends to produce sharper intervals when trained well.\")\n",
        "    print(\" - SARIMAX: classical, may be competitive for linear seasonal series; intervals are parametric and rely on model assumptions.\")\n",
        "    if PROPHET_AVAILABLE:\n",
        "        print(\" - Prophet: robust for trend+seasonality and business time series; uncertainty is based on simulated components and may be wider/narrower depending on trend assumptions.\")\n",
        "    print(\"\\nPractical next steps:\")\n",
        "    print(\" 1) If ICP significantly below nominal -> increase model capacity or use ensembling/heteroscedastic modeling.\")\n",
        "    print(\" 2) If MIW too large -> retrain quantile model with stronger regularization or add relevant predictors.\")\n",
        "    print(\" 3) Cross-validate interval calibration using rolling-window CV and adjust quantile calibration post-hoc if necessary.\")\n",
        "    print(\"\\n=================================================================\\n\")\n",
        "\n",
        "print_analysis(results, uq_results)\n"
      ]
    }
  ]
}